{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "# This functions are to plot the graphs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# By here\n",
    "# This functions are to do mapping\n",
    "import numpy as np\n",
    "import json\n",
    "import folium\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)\n",
    "# By here\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import platform\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    print('Unknown system... sorry~~~~')\n",
    "#### The above code is to set up the font and validate the KOREAN\n",
    "\n",
    "# This is to test to call the excel files\n",
    "glob.glob('D:\\\\OneDrive-Jongki\\\\OneDrive - Illinois Institute of Technology\\\\Jongki-study\\\\05_Manual\\\\17_Python\\\\DataScience\\\\data\\\\Downloaded\\\\지역*.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to call the excel filess\n",
    "station_files = glob.glob('D:\\\\OneDrive-Jongki\\\\OneDrive - Illinois Institute of Technology\\\\Jongki-study\\\\05_Manual\\\\17_Python\\\\DataScience\\\\data\\\\Downloaded\\\\지역*.xls')\n",
    "print(station_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This work is to merge all excel files in 'station_files'\n",
    "# Need to install 'xlrd'\n",
    "tmp_raw = []\n",
    "for file_name in station_files:\n",
    "    # This is to skip the first two rows because they are nothing\n",
    "    tmp = pd.read_excel(file_name, header=2)\n",
    "    tmp_raw.append(tmp)\n",
    "\n",
    "station_raw = pd.concat(tmp_raw)\n",
    "print(station_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(station_raw.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(station_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to re-organize the data, 'station', having only few items to meet the purpose of this study\n",
    "station = pd.DataFrame({'Store':station_raw['상호'], 'Address':station_raw['주소'],'Price':station_raw['휘발유'],'Self':station_raw['셀프여부'],'Brand':station_raw['상표']})\n",
    "print(station.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to make a column for '구'\n",
    "# For this, we use 'eachAddress.split()' function\n",
    "# Among 'Address' which is in 'station', we split the words which is distinguishable by space\n",
    "station['구'] = [eachAddress.split()[1] for eachAddress in station['Address']]\n",
    "print(station.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have a big data set, we need to check a data whether there is a duplicate name or a unwanted subject\n",
    "station['구'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how to filter the unwanted subeject\n",
    "# Let's assume there is '1' in front of '서울특별시' which makes a return as '서울특별시' when we run 'station['구'] = [eachAddress.split()[1] for eachAddress in station['Address']]'\n",
    "# station[station['구]=='서울특별시']\n",
    "\n",
    "# AND THEN\n",
    "# station.loc[station['구]=='서울특별시', '구'] = '성동구'\n",
    "# station['구'].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to rename '구' to 'District'\n",
    "station.rename(columns={station.columns[5]:'District'}, inplace=True)\n",
    "print(station.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF there is a store doesn't report a price and they set as '-'\n",
    "# station[station['Price']=='-']\n",
    "\n",
    "# AND THEN, it is to exclude the data without price information\n",
    "# station = staion[station['Price'] != '-']\n",
    "# station.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to replace the data type in 'Price' to 'float'\n",
    "station['Price'] = [float(value) for value in station['Price']]\n",
    "\n",
    "# This is to reset the index because it may contain redundant items \n",
    "station.reset_index(inplace=True)\n",
    "del station['index']\n",
    "station.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station.boxplot(column='Price', by='Self', figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='Brand', y='Price', hue='Self', data=station, palette='Set3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='Brand', y='Price', data=station, palette='Set3')\n",
    "sns.swarmplot(x='Brand', y='Price', data=station, color='.6')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(station.sort_values(by='Price', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gu_data = pd.pivot_table(station, index=['District'], values=['Price'], aggfunc=np.mean)\n",
    "print(gu_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_path = 'D:\\\\OneDrive-Jongki\\\\OneDrive - Illinois Institute of Technology\\\\Jongki-study\\\\05_Manual\\\\17_Python\\\\DataScience\\\\data\\\\02. skorea_municipalities_geo_simple.json'\n",
    "geo_str = json.load(open(geo_path, encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(loaction=[37.5502, 126.982], zoom_start=100)\n",
    "map.choropleth(geo_data = geo_str, data = gu_data['Price'], columns=[gu_data.index, gu_data['Price']], key_on='feature.id')\n",
    "map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
